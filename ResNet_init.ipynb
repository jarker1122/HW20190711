{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet_init.ipynb","version":"0.3.2","provenance":[{"file_id":"1VL1sK4Hz_IsuhkyQRc8h2SD3w90OF1yp","timestamp":1526642217104}],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"gX3SX-Y5Kh1A","outputId":"96e190a0-27c5-4576-c23a-05529840379d","executionInfo":{"status":"ok","timestamp":1563295857266,"user_tz":-480,"elapsed":60490,"user":{"displayName":"葉鴻","photoUrl":"","userId":"12662670691185209295"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 130963 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q_CYfcCGvuh1","colab_type":"code","colab":{}},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Yu0RHUHxenA","colab_type":"code","outputId":"4f50ffea-e1c0-4f41-9e9f-6347383bb08a","executionInfo":{"status":"ok","timestamp":1563295861723,"user_tz":-480,"elapsed":64920,"user":{"displayName":"葉鴻","photoUrl":"","userId":"12662670691185209295"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["adc.json  drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R8oDguxFxtVX","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"drive\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHQQz6tFxwQa","colab_type":"code","outputId":"8dff29cf-cc81-4d6b-ec54-437c9d24d5ba","executionInfo":{"status":"ok","timestamp":1563295864692,"user_tz":-480,"elapsed":67867,"user":{"displayName":"葉鴻","photoUrl":"","userId":"12662670691185209295"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":[" 1031驗收.rar\t\t\t   minecraft.rar\n"," 2018-12-19.rar\t\t\t   Produce.wmv\n"," 6410609_obser_s.rar\t\t  'RFID (2).rar'\n"," 8051.rar\t\t\t   RFID.rar\n"," c\t\t\t\t  'Serial Key Pro 12.4.rar'\n"," c.7z\t\t\t\t   TA-簽到簿.xlsx\n"," co\t\t\t\t   u0521125\n","'Colab Notebooks'\t\t   務聯網期末專題.rar\n"," Dev-Cpp\t\t\t   寒訓python程式簡報.pptx\n"," drive\t\t\t\t  '科技部計畫(心血管初研究步了解).docx'\n"," DSC_0732-okokok.jpg\t\t   第一次實驗.rar\n","'HW3 4.7z'\t\t\t   第五組.wmv\n"," IMG_0354.JPG\t\t\t   藍芽\n"," IMG_0358.JPG\t\t\t   講義.rar\n","'KartRider Evolved KR.7z 的副本'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uJp1jEhLx8pr","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"Colab Notebooks\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttbA5cBcyHD5","colab_type":"code","outputId":"ce6ff94c-f04c-4acf-f7c7-90689bf7dbe1","executionInfo":{"status":"ok","timestamp":1563295867239,"user_tz":-480,"elapsed":70394,"user":{"displayName":"葉鴻","photoUrl":"","userId":"12662670691185209295"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!ls"],"execution_count":7,"outputs":[{"output_type":"stream","text":[" AlexNet.ipynb\t ResNet_init.ipynb\t        train.txt\n"," drive\t\t'“TensorFlow with GPU”的副本'   Untitled0.ipynb\n"," images\t\t test.txt\t\t        val.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1563295868681,"user_tz":-480,"elapsed":71829,"user":{"displayName":"葉鴻","photoUrl":"","userId":"12662670691185209295"}},"id":"Hr6uu3lMzh0M","outputId":"08a5288d-a5a8-41fd-a39b-08bd0c77e420","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import tensorflow as tf\n","import numpy as np\n","import os, pdb\n","import cv2\n","import numpy as np\n","import random as rn\n","import tensorflow as tf\n","import threading\n","import time\n","\n","global n_classes, layer_count \n","n_classes = 100\n","layer_count = 0\n","\n","'''\n","LOG_DIR = '/tmp/log2'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","\n","#======================Only needed in colab===================================\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip\n","get_ipython().system_raw('./ngrok http 6006 &')\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n","#======================Only needed in colab===================================\n","'''"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nLOG_DIR = \\'/tmp/log2\\'\\nget_ipython().system_raw(\\n    \\'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &\\'\\n    .format(LOG_DIR)\\n)\\n\\n#======================Only needed in colab===================================\\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\\n!unzip -o ngrok-stable-linux-amd64.zip\\nget_ipython().system_raw(\\'./ngrok http 6006 &\\')\\n!curl -s http://localhost:4040/api/tunnels | python3 -c     \"import sys, json; print(json.load(sys.stdin)[\\'tunnels\\'][0][\\'public_url\\'])\"\\n#======================Only needed in colab===================================\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tCNUC9U1zh0U","colab":{}},"source":["#==========================================================================\n","#=============Reading data in multithreading manner========================\n","#==========================================================================\n","def read_labeled_image_list(image_list_file, training_img_dir):\n","    \"\"\"Reads a .txt file containing pathes and labeles\n","    Args:\n","       image_list_file: a .txt file with one /path/to/image per line\n","       label: optionally, if set label will be pasted after each line\n","    Returns:\n","       List with all filenames in file image_list_file\n","    \"\"\"\n","    f = open(image_list_file, 'r')\n","    filenames = []\n","    labels = []\n","\n","    for line in f:\n","        filename, label = line[:-1].split(' ')\n","        filename = training_img_dir+filename\n","        filenames.append(filename)\n","        labels.append(int(label))\n","        \n","    return filenames, labels\n","    \n","    \n","def read_images_from_disk(input_queue, size1=256):\n","    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n","    Args:\n","      filename_and_label_tensor: A scalar string tensor.\n","    Returns:\n","      Two tensors: the decoded image, and the string label.\n","    \"\"\"\n","    label = input_queue[1]\n","    fn=input_queue[0]\n","    file_contents = tf.read_file(input_queue[0])\n","    example = tf.image.decode_jpeg(file_contents, channels=3)\n","    \n","    #example = tf.image.decode_png(file_contents, channels=3, name=\"dataset_image\") # png fo rlfw\n","    example=tf.image.resize_images(example, [size1,size1])\n","    return example, label, fn\n","\n","def setup_inputs(sess, filenames, training_img_dir, image_size=256, crop_size=224, isTest=False, batch_size=64):\n","    \n","    # Read each image file\n","    image_list, label_list = read_labeled_image_list(filenames, training_img_dir)\n","\n","    images = tf.cast(image_list, tf.string)\n","    labels = tf.cast(label_list, tf.int64)\n","     # Makes an input queue\n","    if isTest is False:\n","        isShuffle = True\n","        numThr = 4\n","    else:\n","        isShuffle = False\n","        numThr = 1\n","        \n","    input_queue = tf.train.slice_input_producer([images, labels], shuffle=isShuffle)\n","    image, y,fn = read_images_from_disk(input_queue)\n","\n","    channels = 3\n","    image.set_shape([None, None, channels])\n","        \n","    # Crop and other random augmentations\n","    if isTest is False:\n","        image = tf.image.random_flip_left_right(image)\n","        image = tf.image.random_flip_up_down(image)\n","        image = tf.image.random_hue(image,0.05)\n","        image = tf.image.random_saturation(image, .95, 1.05)\n","        image = tf.image.random_brightness(image, .05)\n","        image = tf.image.random_contrast(image, .95, 1.05)\n","    \n","        \n","\n","    image = tf.random_crop(image, [crop_size, crop_size, 3])\n","    image = tf.cast(image, tf.float32)/255.0\n","    \n","    image, y,fn = tf.train.batch([image, y, fn], batch_size=batch_size, capacity=batch_size*3, num_threads=numThr, name='labels_and_images')\n","\n","    tf.train.start_queue_runners(sess=sess)\n","\n","    return image, y, fn, len(label_list)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zyjBt-MqVce6","colab":{}},"source":["def initializer(in_filters, out_filters,name='wb', ks=3):\n","    W = tf.get_variable(name+\"W\", [3,3, in_filters,out_filters], initializer=tf.truncated_normal_initializer())\n","    b = tf.get_variable(name+\"B\", [out_filters], initializer=tf.truncated_normal_initializer())\n","    return W, b\n","\n","def activation(x,name=\"activation\"):\n","    return tf.nn.relu(x, name=name)\n","    \n","def conv2d(name, l_input, w, b, s, p):\n","    l_input = tf.nn.conv2d(l_input, w, strides=[1,s,s,1], padding=p, name=name)\n","    l_input = l_input+b\n","\n","    return l_input\n","  \n","def init_tensor(shape):\n","    return tf.Variable(tf.truncated_normal(shape, mean=0.0, stddev=1.0))\n","  \n","def _conv(input, filter_shape, stride):\n","    return tf.nn.conv2d(input,filter=init_tensor(filter_shape),strides=[1, stride, stride, 1],padding='SAME')\n","    \n","def _batch_norm(input_):\n","    assert len(input_.get_shape()) == 4\n","    filter_shape = input_.get_shape().as_list()\n","    mean, var = tf.nn.moments(input_, axes=[0, 1, 2])\n","    out_channels = filter_shape[3]\n","    offset = tf.Variable(tf.zeros([out_channels]))\n","    scale = tf.Variable(tf.ones([out_channels]))\n","    batch_norm = tf.nn.batch_normalization(input_, mean, var, offset, scale, 0.001)\n","    return batch_norm\n","\n","def max_pool(name, l_input, k, s):\n","    return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding='VALID', name=name)\n","\n","def batchnorm(conv, isTraining, name='bn'):\n","    return tf.layers.batch_normalization(conv, momentum = 0.997, training=isTraining, name=\"bn\"+name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"94VSiHqhzh0S","colab":{}},"source":["\n","  \n","def residual_block(in_x, in_filters, out_filters, stride, tst, name):\n","    # first convolution layer\n","    global layer_count\n","    x =_batch_norm(in_x)\n","    x = activation(x)\n","    x = _conv(x, [3, 3, in_filters, out_filters], stride)\n","    # second convolution layer\n","    x = _batch_norm(x)\n","    x = activation(x)\n","    x = _conv(x, [3, 3, in_filters, out_filters], stride)\n","    ##\"How to have skip connection?\"\n","    if in_filters != out_filters:\n","        difference = out_filters - in_filters\n","        left_pad = difference // 2\n","        right_pad = difference - left_pad\n","        identity = tf.pad(in_x, [[0, 0], [0, 0], [0, 0], [left_pad, right_pad]])  \n","        return identity + x \n","    else:\n","        return in_x + x \n","\n","      \n","def ResNet(_X, tst):\n","    global n_classes\n","    w1 = tf.get_variable(\"firstW\", [7,7,3, 64], initializer=tf.truncated_normal_initializer())\n","    b1 = tf.get_variable(\"firstB\", [64], initializer=tf.truncated_normal_initializer())\n","    \n","    x = conv2d('conv1', _X, w1, b1, 3, \"VALID\")\n","    x = batchnorm(x, tst, name='sbn')\n","    x= tf.nn.relu(x)\n","    \n","    filters_num = [64,128,256,512]\n","    block_num = [3,4,6,3]\n","    strides=[1,1,1,1]\n","    l_cnt = 1\n","    for i in range(len(filters_num)):\n","      for j in range(block_num[i]):\n","          x = residual_block(x, filters_num[i], filters_num[i], strides[i], tst, 'RB%d_%d'%(i,j))\n","          print('[L-%d] Build %dth residual block %d with %d channels' % (l_cnt,i, j, filters_num[i]))\n","          l_cnt +=1\n","          if ((j==block_num[i]-1) & (i<len(filters_num)-1)):\n","            x = batchnorm(x, tst, name='RB_bn%d_%d'%(i,j))\n","            w1, b1 = initializer(filters_num[i], filters_num[i+1], name='RB_pool%d_%d'%(i,j))\n","            x = conv2d('RB_pool%d_%d'%(i,j), x, w1, b1, 2, \"VALID\")\n","            x = activation(x)\n","            print('[L-%d] Build %dth connection layer %d from %d to %d channels' % (l_cnt, i, j, filters_num[i], filters_num[i+1]))\n","            l_cnt +=1\n","\n","    wo, bo=initializer(filters_num[-1], n_classes, name='final_wb')\n","    x = conv2d('final', x, wo, bo, 1, \"SAME\")\n","    x = batchnorm(x, tst, name=\"final_bn1\")\n","    x = activation(x, name='final_act')\n","    \n","    x = tf.reduce_mean(x, [1,2]) #b x7 x 7 x 50 ==> b x 1 x 1 x 50==>b x 50 ==> b x 50\n","    W = tf.get_variable(\"FinalW\", [n_classes, n_classes], initializer=tf.truncated_normal_initializer())\n","    b = tf.get_variable(\"FinalB\", [n_classes], initializer=tf.truncated_normal_initializer())\n","    \n","    out = tf.matmul(x, W) + b\n","                            \n","\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h7AtFd4czh0W","colab":{}},"source":["batch_size = 64\n","display_step = 80\n","learning_rate = tf.placeholder(tf.float32)      # Learning rate to be fed\n","lr = 1e-3              # Learning rate start\n","tst = tf.placeholder(tf.bool)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1563295879835,"user_tz":-480,"elapsed":82949,"user":{"displayName":"葉鴻","photoUrl":"","userId":"12662670691185209295"}},"id":"7LCc7xsQzh0Y","outputId":"bdb6eb10-c726-4f57-fe18-1533af816bce","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Setup the tensorflow...\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.Session(config=config)\n","\n","print(\"Preparing the training & validation data...\")\n","train_data, train_labels, filelist1, glen1 = setup_inputs(sess, \"train.txt\", \"\", batch_size=batch_size)\n","val_data, val_labels, filelist2, tlen1 = setup_inputs(sess, \"val.txt\", \"\",isTest=True, batch_size=batch_size)\n","\n","max_iter = glen1*400\n","print(\"Preparing the training model with learning rate = %.5f...\" % (lr))\n","\n","\n","with tf.variable_scope(\"ResNet\") as scope:\n","  pred = ResNet(train_data, True)\n","  scope.reuse_variables()\n","  valpred = ResNet(val_data, False)\n","\n","with tf.name_scope('Loss_and_Accuracy'):\n","  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","  with tf.control_dependencies(update_ops):\n","    cost = tf.losses.sparse_softmax_cross_entropy(labels=train_labels, logits=pred)\n","    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n","    \n","  correct_prediction = tf.equal(tf.argmax(pred, 1), train_labels)\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","  \n","  correct_prediction2 = tf.equal(tf.argmax(valpred,1), val_labels)\n","  accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))\n","  \n","  tf.summary.scalar('Loss', cost)\n","  tf.summary.scalar('Training_Accuracy', accuracy)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Preparing the training & validation data...\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0716 16:51:11.136657 139812445833088 deprecation.py:323] From <ipython-input-9-4690a01bcc50>:53: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0716 16:51:11.146816 139812445833088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0716 16:51:11.165044 139812445833088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0716 16:51:11.168424 139812445833088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n","W0716 16:51:11.173826 139812445833088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0716 16:51:11.177789 139812445833088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0716 16:51:11.244895 139812445833088 deprecation.py:323] From <ipython-input-9-4690a01bcc50>:73: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n","W0716 16:51:11.255974 139812445833088 deprecation.py:323] From <ipython-input-9-4690a01bcc50>:75: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n"],"name":"stderr"},{"output_type":"stream","text":["Preparing the training model with learning rate = 0.00100...\n"],"name":"stdout"},{"output_type":"stream","text":["W0716 16:51:12.798907 139812445833088 deprecation.py:323] From <ipython-input-10-384464ba8d42>:35: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"],"name":"stderr"},{"output_type":"stream","text":["[L-1] Build 0th residual block 0 with 64 channels\n","[L-2] Build 0th residual block 1 with 64 channels\n","[L-3] Build 0th residual block 2 with 64 channels\n","[L-4] Build 0th connection layer 2 from 64 to 128 channels\n","[L-5] Build 1th residual block 0 with 128 channels\n","[L-6] Build 1th residual block 1 with 128 channels\n","[L-7] Build 1th residual block 2 with 128 channels\n","[L-8] Build 1th residual block 3 with 128 channels\n","[L-9] Build 1th connection layer 3 from 128 to 256 channels\n","[L-10] Build 2th residual block 0 with 256 channels\n","[L-11] Build 2th residual block 1 with 256 channels\n","[L-12] Build 2th residual block 2 with 256 channels\n","[L-13] Build 2th residual block 3 with 256 channels\n","[L-14] Build 2th residual block 4 with 256 channels\n","[L-15] Build 2th residual block 5 with 256 channels\n","[L-16] Build 2th connection layer 5 from 256 to 512 channels\n","[L-17] Build 3th residual block 0 with 512 channels\n","[L-18] Build 3th residual block 1 with 512 channels\n","[L-19] Build 3th residual block 2 with 512 channels\n","[L-1] Build 0th residual block 0 with 64 channels\n","[L-2] Build 0th residual block 1 with 64 channels\n","[L-3] Build 0th residual block 2 with 64 channels\n","[L-4] Build 0th connection layer 2 from 64 to 128 channels\n","[L-5] Build 1th residual block 0 with 128 channels\n","[L-6] Build 1th residual block 1 with 128 channels\n","[L-7] Build 1th residual block 2 with 128 channels\n","[L-8] Build 1th residual block 3 with 128 channels\n","[L-9] Build 1th connection layer 3 from 128 to 256 channels\n","[L-10] Build 2th residual block 0 with 256 channels\n","[L-11] Build 2th residual block 1 with 256 channels\n","[L-12] Build 2th residual block 2 with 256 channels\n","[L-13] Build 2th residual block 3 with 256 channels\n","[L-14] Build 2th residual block 4 with 256 channels\n","[L-15] Build 2th residual block 5 with 256 channels\n","[L-16] Build 2th connection layer 5 from 256 to 512 channels\n","[L-17] Build 3th residual block 0 with 512 channels\n","[L-18] Build 3th residual block 1 with 512 channels\n","[L-19] Build 3th residual block 2 with 512 channels\n"],"name":"stdout"},{"output_type":"stream","text":["W0716 16:51:15.053116 139812445833088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3CGfQ_Cbzh0c","outputId":"8de7d5ee-4b01-4718-c680-fb5d0b93dff7","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","sess.run(init)\n","step = 0\n","writer = tf.summary.FileWriter(\"/tmp/log2\", sess.graph)\n","summaries = tf.summary.merge_all()\n","\n","print(\"We are going to train the ImageNet model based on ResNet!!!\")\n","while (step * batch_size) < max_iter:\n","    epoch1=np.floor((step*batch_size)/glen1)\n","    if (((step*batch_size)%glen1 < batch_size) & (lr==1e-3) & (epoch1 >2)):\n","        lr /= 10\n","\n","    sess.run(optimizer,  feed_dict={learning_rate: lr, tst: True})\n","\n","    if (step % 15000==1) & (step>15000):\n","        save_path = saver.save(sess, \"checkpoint/tf_resnet_model_iter\" + str(step) + \".ckpt\")\n","        print(\"Model saved in file at iteration %d: %s\" % (step*batch_size,save_path))\n","\n","    if step % display_step == 1:\n","        # calculate the loss\n","        \n","        loss, acc, summaries_string = sess.run([cost, accuracy, summaries], feed_dict={ tst: True})\n","        print(\"Iter=%d/epoch=%d, Loss=%.6f, Training Accuracy=%.6f, lr=%f\" % (step*batch_size, epoch1 ,loss, acc, lr))\n","        writer.add_summary(summaries_string, step)\n","        \n","#         if step*batch_size==82048:\n","#         import pdb\n","#         pdb.set_trace()\n","\n","  \n","    step += 1\n","print(\"Optimization Finished!\")\n","save_path = saver.save(sess, \"checkpoint/tf_resnet_model.ckpt\")\n","print(\"Model saved in file: %s\" % save_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["We are going to train the ImageNet model based on ResNet!!!\n","Iter=64/epoch=0, Loss=8.713903, Training Accuracy=0.000000, lr=0.001000\n","Iter=5184/epoch=0, Loss=4.714976, Training Accuracy=0.046875, lr=0.001000\n","Iter=10304/epoch=0, Loss=3.870954, Training Accuracy=0.062500, lr=0.001000\n","Iter=15424/epoch=0, Loss=3.982466, Training Accuracy=0.046875, lr=0.001000\n","Iter=20544/epoch=0, Loss=3.704814, Training Accuracy=0.031250, lr=0.001000\n","Iter=25664/epoch=0, Loss=3.859193, Training Accuracy=0.046875, lr=0.001000\n","Iter=30784/epoch=0, Loss=3.535327, Training Accuracy=0.109375, lr=0.001000\n","Iter=35904/epoch=0, Loss=3.424048, Training Accuracy=0.140625, lr=0.001000\n","Iter=41024/epoch=0, Loss=3.490769, Training Accuracy=0.093750, lr=0.001000\n","Iter=46144/epoch=0, Loss=3.611406, Training Accuracy=0.078125, lr=0.001000\n","Iter=51264/epoch=0, Loss=3.323308, Training Accuracy=0.140625, lr=0.001000\n","Iter=56384/epoch=0, Loss=3.345434, Training Accuracy=0.078125, lr=0.001000\n","Iter=61504/epoch=0, Loss=3.428489, Training Accuracy=0.140625, lr=0.001000\n","Iter=66624/epoch=1, Loss=3.011079, Training Accuracy=0.140625, lr=0.001000\n","Iter=71744/epoch=1, Loss=2.943066, Training Accuracy=0.250000, lr=0.001000\n","Iter=76864/epoch=1, Loss=3.131974, Training Accuracy=0.156250, lr=0.001000\n"],"name":"stdout"},{"output_type":"stream","text":["E0717 00:30:14.104163 139809513862912 queue_runner_impl.py:275] Exception in QueueRunner: 2 root error(s) found.\n","  (0) Failed precondition: images/n02113799/n02113799_119.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","\t [[resize/ResizeBilinear/_17]]\n","  (1) Failed precondition: images/n02113799/n02113799_119.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","E0717 00:30:14.212041 139809530648320 queue_runner_impl.py:275] Exception in QueueRunner: 2 root error(s) found.\n","  (0) Failed precondition: images/n02120079/n02120079_1769.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","  (1) Failed precondition: images/n02120079/n02120079_1769.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","\t [[resize/ResizeBilinear/_17]]\n","0 successful operations.\n","0 derived errors ignored.\n","Exception in thread QueueRunnerThread-labels_and_images/fifo_queue-labels_and_images/fifo_queue_enqueue:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n","    enqueue_callable()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1279, in _single_operation_run\n","    self._call_tf_sessionrun(None, {}, [], target_list, None)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.\n","  (0) Failed precondition: images/n02120079/n02120079_1769.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","  (1) Failed precondition: images/n02120079/n02120079_1769.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","\t [[resize/ResizeBilinear/_17]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Exception in thread QueueRunnerThread-labels_and_images/fifo_queue-labels_and_images/fifo_queue_enqueue:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n","    enqueue_callable()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1279, in _single_operation_run\n","    self._call_tf_sessionrun(None, {}, [], target_list, None)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.\n","  (0) Failed precondition: images/n02113799/n02113799_119.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","\t [[resize/ResizeBilinear/_17]]\n","  (1) Failed precondition: images/n02113799/n02113799_119.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","E0717 00:30:14.391810 139809522255616 queue_runner_impl.py:275] Exception in QueueRunner: images/n02111500/n02111500_7876.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","Exception in thread QueueRunnerThread-labels_and_images/fifo_queue-labels_and_images/fifo_queue_enqueue:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n","    enqueue_callable()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1279, in _single_operation_run\n","    self._call_tf_sessionrun(None, {}, [], target_list, None)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.FailedPreconditionError: images/n02111500/n02111500_7876.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","\n","E0717 00:30:14.395292 139809539041024 queue_runner_impl.py:275] Exception in QueueRunner: images/n02113799/n02113799_1609.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","Exception in thread QueueRunnerThread-labels_and_images/fifo_queue-labels_and_images/fifo_queue_enqueue:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n","    enqueue_callable()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1279, in _single_operation_run\n","    self._call_tf_sessionrun(None, {}, [], target_list, None)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.FailedPreconditionError: images/n02113799/n02113799_1609.JPEG; Transport endpoint is not connected\n","\t [[{{node ReadFile}}]]\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AOQOeejKzh0f","colab":{}},"source":["exit()"],"execution_count":0,"outputs":[]}]}